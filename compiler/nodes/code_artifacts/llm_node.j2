#{ Template for generating LLM node function with Command pattern - Single Global State #}
def {{ sanitized_label }}_{{ node_id }}_node(global_state: GlobalState) -> Command:
    """LLM Node {{ node_id }}: {{ title }}"""
    
    # Build message list
    messages = []

    # Get conversation history from node-specific messages in global state
    node_messages = global_state.get("node_{{ node_id }}_messages", [])

    if len(node_messages) == 0:
        # FIRST INVOCATION ONLY - add system and human prompts
        system_prompt_rendered = render_template({{ system_prompt|tojson }}, global_state)
        if system_prompt_rendered:
            messages.append(SystemMessage(content=system_prompt_rendered))

        # Add human prompt if provided
        human_prompt_rendered = render_template({{ human_prompt|tojson }}, global_state)
        if human_prompt_rendered:
            # Append input state keys to human message
            human_message_content = human_prompt_rendered

            {%- if input_state_keys %}
            # Add input state keys section
            human_message_content += "\n\n## Input:\n"
            {%- for key in input_state_keys %}
            human_message_content += f"\n### {{ key }}:\n{global_state.get('{{ key }}', 'Not available')}\n"
            {%- endfor %}
            {%- endif %}

            messages.append(HumanMessage(content=human_message_content))
        {%- if input_state_keys and not human_prompt %}
        else:
            # Only input state keys, no human prompt
            human_message_content = "## Input:\n"
            {%- for key in input_state_keys %}
            human_message_content += f"\n### {{ key }}:\n{global_state.get('{{ key }}', 'Not available')}\n"
            {%- endfor %}
            messages.append(HumanMessage(content=human_message_content))
        {%- endif %}
    else:
        # SUBSEQUENT INVOCATIONS - use existing conversation history
        messages.extend(node_messages)
    
    {% if has_tools %}
    # TWO-PHASE EXECUTION: Check if returning from tool iteration
    current_iteration = global_state.get("node_{{ node_id }}_tool_iteration_count", 0)

    if current_iteration > 0:
        # Coming back from tool execution

        # ADD WARNING BEFORE INVOKING MODEL (if approaching limit)
        max_iterations = {{ max_tool_iterations }}
        if current_iteration >= max_iterations - 3 and current_iteration < max_iterations:
            remaining = max_iterations - current_iteration
            warning_msg = HumanMessage(
                content="{{ iteration_warning_message }}"
            )
            messages.append(warning_msg)

        # Now apply structured output to get final response
        model_with_output = model_{{ node_id }}.with_structured_output({{ structured_output_schema_class }})
        if LANGFUSE_HANDLER:
            structured_response = model_with_output.invoke(messages, config={"callbacks": [LANGFUSE_HANDLER]})
        else:
            structured_response = model_with_output.invoke(messages)
        
        state_updates = {
            "count": 1,
            "messages": [AIMessage(content=str(structured_response))],
            "node_{{ node_id }}_messages": [AIMessage(content=str(structured_response))],
            "node_{{ node_id }}_llm_calls": 1,
            "node_{{ node_id }}_tool_iteration_count": 0
        }
        
        {%- if output_state_keys %}
        # Extract and validate output state keys
        {%- for key in output_state_keys %}
        if not hasattr(structured_response, '{{ key }}'):
            raise ValueError(f"Output field '{{ key }}' not found in structured output from node {{ node_id }}")
        state_updates['{{ key }}'] = getattr(structured_response, '{{ key }}')
        {%- endfor %}
        {%- endif %}
        
        return Command(
            update=state_updates,
            goto="{{ next_node }}"
        )
    
    # First invocation - invoke model WITHOUT structured output to allow tool calls
    if LANGFUSE_HANDLER:
        response = model_{{ node_id }}.invoke(messages, config={"callbacks": [LANGFUSE_HANDLER]})
    else:
        response = model_{{ node_id }}.invoke(messages)
    
    # Check if response contains tool calls
    if hasattr(response, 'tool_calls') and response.tool_calls:
        # Has tool calls - route to tool node for execution
        return Command(
            update={
                "count": 1,
                "messages": [response],
                "node_{{ node_id }}_messages": [response],
                "node_{{ node_id }}_llm_calls": 1
            },
            goto="tool_{{ node_id }}_node"
        )
    
    # No tool calls on first try - apply structured output
    messages.append(response)
    messages.append(HumanMessage(
        content="Please format your previous response according to the required output schema."
    ))

    model_with_output = model_{{ node_id }}.with_structured_output({{ structured_output_schema_class }})
    if LANGFUSE_HANDLER:
        structured_response = model_with_output.invoke(messages, config={"callbacks": [LANGFUSE_HANDLER]})
    else:
        structured_response = model_with_output.invoke(messages)
    
    state_updates = {
        "count": 1,
        "messages": [AIMessage(content=str(structured_response))],
        "node_{{ node_id }}_messages": [AIMessage(content=str(structured_response))],
        "node_{{ node_id }}_llm_calls": 1,
        "node_{{ node_id }}_tool_iteration_count": 0
    }
    
    {%- if output_state_keys %}
    # Extract and validate output state keys
    {%- for key in output_state_keys %}
    if not hasattr(structured_response, '{{ key }}'):
        raise ValueError(f"Output field '{{ key }}' not found in structured output from node {{ node_id }}")
    state_updates['{{ key }}'] = getattr(structured_response, '{{ key }}')
    {%- endfor %}
    {%- endif %}
    
    return Command(
        update=state_updates,
        goto="{{ next_node }}"
    )
    
    {% else %}
    # No tools - directly apply structured output
    model_with_output = model_{{ node_id }}.with_structured_output({{ structured_output_schema_class }})
    if LANGFUSE_HANDLER:
        response = model_with_output.invoke(messages, config={"callbacks": [LANGFUSE_HANDLER]})
    else:
        response = model_with_output.invoke(messages)
    
    # Extract output state keys and validate
    state_updates = {
        "count": 1,
        "messages": [AIMessage(content=str(response))],
        "node_{{ node_id }}_messages": [AIMessage(content=str(response))],
        "node_{{ node_id }}_llm_calls": 1
    }
    
    {%- if output_state_keys %}
    # Extract and validate output state keys
    {%- for key in output_state_keys %}
    if not hasattr(response, '{{ key }}'):
        raise ValueError(f"Output field '{{ key }}' not found in structured output from node {{ node_id }}")
    state_updates['{{ key }}'] = getattr(response, '{{ key }}')
    {%- endfor %}
    {%- endif %}
    
    return Command(
        update=state_updates,
        goto="{{ next_node }}"
    )
    {% endif %}
